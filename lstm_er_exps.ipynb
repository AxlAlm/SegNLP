{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "from segnlp import Pipeline\n",
    "from segnlp.datasets.am import PE\n",
    "from segnlp.pretrained_features import GloveEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing and Storing Dataset: 100%|██████████| 402/402 [01:07<00:00,  5.96it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# setting up the pipeline      \n",
    "exp = Pipeline(\n",
    "                id=\"lstm_er_pe\", # will create folder at with id as name at ~/.segnlp/<id>/ \n",
    "                dataset=PE(\n",
    "                    tasks=[\"seg+label\", \"link\", \"link_label\"],\n",
    "                    prediction_level=\"token\",\n",
    "                    sample_level=\"document\",\n",
    "                ),\n",
    "                metric = \"overlap_metric\", # settting metric, can be found in segnlp.metrics\n",
    "                model = \"LSTM_ER\",\n",
    "                pretrained_features = [\n",
    "                                GloveEmbeddings(),\n",
    "                            ],\n",
    "                #overwrite = True, # will remove folder at ~/.segnlp/<id> and create new one\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparamaters\n",
    "# one set of hyperparamaters per layer + general hyperaparamaters\n",
    "\n",
    "import gensim.downloader as api\n",
    "\n",
    "\n",
    "hps = {\n",
    "        \"general\":{\n",
    "                \"optimizer\": {\n",
    "                                \"name\":\"Adam\",\n",
    "                                \"lr\": 0.001,\n",
    "                                \"weight_decay\":1e-5\n",
    "                                },\n",
    "                \"batch_size\": 1,\n",
    "                \"max_epochs\":100,\n",
    "                \"patience\": 10,\n",
    "                \"task_weight\": 0.5,\n",
    "                \"use_target_segs_k\": 10, # sampling\n",
    "                \"freeze_segment_module_k\": 25, # Havent tested this fully yet. (Next on the list)\n",
    "                \"gradient_clip_val\": 10.0\n",
    "                },\n",
    "        \"dropout\": {\n",
    "                        \"p\":0.5\n",
    "                },\n",
    "        \"output_dropout\": {\n",
    "                        \"p\": 0.3\n",
    "                        },\n",
    "        \"word_embs\": {\n",
    "                        \"vocab\": \"BNC_10k\",\n",
    "                        \"path_to_pretrained\" : api.load(\"glove-wiki-gigaword-50\", return_path=True)\n",
    "                        },\n",
    "        \"pos_embs\":{\n",
    "                        \"vocab\": \"Pos\",\n",
    "                        \"embedding_dim\":25,\n",
    "                        \"weight_init\": \"_uniform\" #random from uniform\n",
    "\n",
    "                },\n",
    "        \"dep_embs\":{\n",
    "                        \"vocab\": \"Pos\",\n",
    "                        \"embedding_dim\":25,\n",
    "                        \"weight_init\": \"_uniform\" #random from uniform\n",
    "                },\n",
    "       \"LSTM\": {   \n",
    "                        \"input_dropout\": 0.5,\n",
    "                        \"dropout\":0.5,\n",
    "                        \"hidden_size\": 100,\n",
    "                        \"num_layers\":1,\n",
    "                        \"bidir\":True,\n",
    "                        \"weight_init\": \"_uniform\" #random from uniform\n",
    "\n",
    "                    },\n",
    "        \"BigramSeg\": {\n",
    "                        \"hidden_size\": 512,\n",
    "                        \"weight_init\": \"_uniform\" #random from uniform\n",
    "\n",
    "                },\n",
    "        \"Agg\":{\n",
    "                \"mode\":\"mean\",\n",
    "                },\n",
    "        \"DepTreeLSTM\": {\n",
    "                        \"hidden_size\":100,\n",
    "                        \"bidir\":True,\n",
    "                        \"mode\": \"shortest_path\",\n",
    "                        \"weight_init\": \"_uniform\" #random from uniform\n",
    "\n",
    "                        },\n",
    "        \"LinearPairEnc\": {\n",
    "                        \"hidden_size\":100,\n",
    "                        \"activation\": \"Tanh\",\n",
    "                        \"weight_init\": \"_uniform\" #random from uniform\n",
    "                        },\n",
    "        \"DirLinkLabeler\": {\n",
    "                            \"match_threshold\": 0.3,\n",
    "                        }\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will train models for each random seed and each set of hyperparamaters given. All models are saved\n",
    "# All outputs are also logged to ~/.segnlp/<id>/logs/<n>.log but havent fully test this either.\n",
    "best_hp = exp.train(\n",
    "                        hyperparamaters = hps,\n",
    "                        n_random_seeds=6,\n",
    "                        monitor_metric=\"val_f1-micro\"\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "\n",
    "\n",
    "# 1 ) Make sure logging of all scores is working\n",
    "# 2 ) finish the code for exp.test()\n",
    "# 3 ) tie the statistical_significance testing fucntions to logs, so one can get the best hyperparamaters\n",
    "#     quicker and also test one model against another\n",
    "# 4)  add some code for plotting logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('segnlp': conda)",
   "name": "python374jvsc74a57bd0a76bc8531fef674196aa7aad9134f25b0cc59176f1f31a4f40d52a7ed7b4acca"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "a76bc8531fef674196aa7aad9134f25b0cc59176f1f31a4f40d52a7ed7b4acca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}