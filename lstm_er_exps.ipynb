{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "from segnlp import Pipeline\n",
    "from segnlp.datasets.am import PE\n",
    "from segnlp.pretrained_features import GloveEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing and Storing Dataset: 100%|██████████| 402/402 [01:07<00:00,  5.96it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# setting up the pipeline      \n",
    "exp = Pipeline(\n",
    "                id=\"lstm_er_pe\", # will create folder at with id as name at ~/.segnlp/<id>/ \n",
    "                dataset=PE(\n",
    "                    tasks=[\"seg+label\", \"link\", \"link_label\"],\n",
    "                    prediction_level=\"token\",\n",
    "                    sample_level=\"document\",\n",
    "                ),\n",
    "                metric = \"overlap_metric\", # settting metric, can be found in segnlp.metrics\n",
    "                model = \"LSTM_ER\",\n",
    "                pretrained_features = [\n",
    "                                GloveEmbeddings(),\n",
    "                            ],\n",
    "                #overwrite = True, # will remove folder at ~/.segnlp/<id> and create new one\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparamaters\n",
    "# one set of hyperparamaters per layer + general hyperaparamaters\n",
    "hps = {\n",
    "        \"general\":{\n",
    "                \"optimizer\": \"Adam\",\n",
    "                \"lr\": 0.001,\n",
    "                \"batch_size\": 32,\n",
    "                \"max_epochs\":100,\n",
    "                \"patience\": 10,\n",
    "                \"task_weight\": 0.5,\n",
    "                \"use_target_segs_k\": 10, # sampling\n",
    "                #\"freeze_segment_module_k\": 5, # Havent tested this fully yet. (Next on the list)\n",
    "                },\n",
    "\n",
    "       \"LSTM\": {   \n",
    "                    \"input_dropout\": 0.5,\n",
    "                    \"dropout\":0.5,\n",
    "                    \"hidden_size\": 100,\n",
    "                    \"num_layers\":1,\n",
    "                    \"bidir\":True,\n",
    "                    },\n",
    "        \"BigramSeg\": {\n",
    "                        \"hidden_size\": 512,\n",
    "                },\n",
    "        \"Agg\":{\n",
    "                \"mode\":\"mean\",\n",
    "                },\n",
    "        \"DepTreeLSTM\": {\n",
    "                        \"dropout\":0.5,\n",
    "                        \"hidden_size\":100,\n",
    "                        \"bidir\":True,\n",
    "                        \"mode\": \"shortest_path\",\n",
    "                        },\n",
    "        \"LinearPairEnc\": {\n",
    "                        \"hidden_size\":100,\n",
    "                        \"activation\": \"Tanh\",\n",
    "                        },\n",
    "        \"DirLinkLabeler\": {\n",
    "                            \"dropout\": 0.5,\n",
    "                            \"match_threshold\": 0.5,\n",
    "                        }\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will train models for each random seed and each set of hyperparamaters given. All models are saved\n",
    "# All outputs are also logged to ~/.segnlp/<id>/logs/<n>.log but havent fully test this either.\n",
    "best_hp = exp.train(\n",
    "                        hyperparamaters = hps,\n",
    "                        n_random_seeds=6,\n",
    "                        monitor_metric=\"val_f1-micro\"\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "\n",
    "\n",
    "# 1 ) Make sure logging of all scores is working\n",
    "# 2 ) finish the code for exp.test()\n",
    "# 3 ) tie the statistical_significance testing fucntions to logs, so one can get the best hyperparamaters\n",
    "#     quicker and also test one model against another\n",
    "# 4)  add some code for plotting logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}